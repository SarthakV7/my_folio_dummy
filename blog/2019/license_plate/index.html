<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Sarthak  Vajpayee | AI-powered Indian license plate detector.</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/my_folio/assets/img/favicon.ico">
<link rel="stylesheet" href="/my_folio/assets/css/main.css">

<link rel="canonical" href="/my_folio/blog/2019/license_plate/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/my_folio/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/my_folio/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/my_folio/">
       <span class="font-weight-bold">Sarthak</span>   Vajpayee
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/my_folio/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/my_folio/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/my_folio/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/my_folio/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/my_folio/teaching/">
                skills
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">AI-powered Indian license plate detector.</h1>
    <p class="post-meta">September 7, 2019</p>
  </header>

  <article class="post-content">
    <div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/3200/1*Fh9BMaEwSRsCFOFvQnC2ww.jpeg" />
    </div>
</div>

<p><img src="" alt="" /></p>

<h4 id="inspiration"><strong>Inspiration:</strong></h4>
<p>The guy who hit my car and got away with it!</p>

<p><img src="" alt="" /></p>

<h4 id="backstory"><strong>Backstory:</strong></h4>
<p>After a memorable evening with friends as we were about to leave for our home there was something that made that evening even more memorable, a huge dent in my car’s front bumper, seemed it was hit by another vehicle, but who to blame? There was no one around who would have witnessed that. And what could I do about it?  I’ll tell you exactly what I did about it. I decided to use my machine learning and data skills and make an AI-based Indian License plate detector that was capable enough to keep a watch on a vehicle by detecting the number plates of vehicles around it and in this blog I’ll be taking you guys through my journey of how I did it! First things first: There is always a scope of improvising, so if you come up with some better ideas or doubts regarding this project please do use the response section below.</p>

<p><img src="" alt="" /></p>

<h3 id="approach">Approach:</h3>

<p><strong>We need to build a system that is capable of -</strong></p>

<ul>
  <li>
    <p>Taking in the image/video (series of images) from surrounding:
at the hardware end, we need a pc (or raspberry pi) along with a camera and at the software end, we need a library to capture and process the data (image). I’ve used OpenCV (4.1.0) and Python (3.6.7) for this project.</p>
  </li>
  <li>
    <p>Looking for a license plate in the image:
To detect an object(license plate) from an image we need another tool that can recognize an Indian license plate so for that I’ve used Haar cascade, pre-trained on Indian license plates (will be updating soon to YOLO v3).</p>
  </li>
  <li>
    <p>Analyzing and performing some image processing on the License plate:
Using OpenCV’s grayscale, threshold, erode, dilate, contour detection and by some parameter tuning, we may easily be able to generate enough information about the plate to decide if the data is useful enough to be passed on to further processes or not (sometime if the image is very distorted or not proper, we may only get suppose 8 out of 10 characters, then there’s no point passing the data down the pipeline but to ignore it and look at the next frame for the plate), also before passing the image to the next process we need to make sure that it is noise-free and processed.</p>
  </li>
  <li>
    <p>Segmenting the alphanumeric characters from the license plate:
if everything in the above steps works fine, we should be ready to extract the characters from the plate, this can be done by thresholding, eroding, dilating and blurring the image skillfully such that at the end the image we have is almost noise-free and easy for further functions to work on. We now again use contour detection and some parameter tuning to extract the characters.</p>
  </li>
  <li>
    <p>Considering the characters one by one, recognizing the characters, concatenating the results and giving out the plate number as a string:
Now comes the fun part! Since we have all the characters, we need to pass the characters one by one into our trained model, and it should recognize the characters and voilà! We’ll be using Keras for our Convolutional Neural Network model.</p>
  </li>
</ul>

<p><img src="" alt="" /></p>

<h3 id="prerequisites">Prerequisites:</h3>

<ul>
  <li>
    <p><strong>OpenCV</strong>: OpenCV is a library of programming functions mainly aimed at real-time computer vision plus its open-source, fun to work with and my personal favorite. I have used version 4.1.0 for this project.</p>
  </li>
  <li>
    <p><strong>Python</strong>: aka swiss army knife of coding. I have used version 3.6.7 here.</p>
  </li>
  <li>
    <p><strong>IDE:</strong> I’ll be using Jupyter here.</p>
  </li>
  <li>
    <p><strong>Haar cascade</strong>: It is a machine learning object detection algorithm used to identify objects in an image or video and based on the concept of <strong>​​</strong> features proposed by Paul Viola and Michael Jones in their paper “Rapid Object Detection using a Boosted Cascade of Simple Features” in 2001. <a href="https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework">More info</a></p>
  </li>
  <li>
    <p><strong>Keras</strong>: Easy to use and widely supported, Keras makes deep learning about as simple as deep learning can be.</p>
  </li>
  <li>
    <p><strong>Scikit-Learn:</strong> It is a free software machine learning library for the Python programming language.</p>
  </li>
  <li>
    <p>And of course, do not forget the <strong>coffee</strong>!</p>
  </li>
</ul>

<p><img src="" alt="" /></p>

<h5 id="step-1"><strong>Step 1</strong></h5>

<blockquote>
  <p><strong>Creating a workspace.</strong></p>
</blockquote>

<p>I recommend making a conda environment because it makes project management much easier. Please follow the instructions in this <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/install/">link</a> for installing miniconda. Once installed open cmd/terminal and create an environment using-</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
</pre></td><td class="code"><pre>    conda create <span class="nt">-n</span> <span class="s1">'name_of_the_environment'</span> <span class="nv">python</span><span class="o">=</span>3.6.7 
</pre></td></tr></tbody></table></code></pre></figure>

<p>Now let’s activate the environment:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
</pre></td><td class="code"><pre>    conda activate <span class="s1">'name_of_the_environment'</span> 
</pre></td></tr></tbody></table></code></pre></figure>

<p>This should set us inside our virtual environment. Time to install some libraries-</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="code"><pre>    <span class="c"># installing OpenCV</span>
    pip <span class="nb">install </span>opencv-python<span class="o">==</span>4.1.0

    <span class="c"># Installing Keras</span>
    pip <span class="nb">install </span>keras

    <span class="c"># Installing Jupyter</span>
    pip <span class="nb">install </span>jupyter

    <span class="c">#Installing Scikit-Learn</span>
    pip <span class="nb">install </span>scikit-learn 
</pre></td></tr></tbody></table></code></pre></figure>

<p><img src="" alt="" /></p>

<h5 id="step-2"><strong>Step 2</strong></h5>
<blockquote>
  <p><strong>Setting up the environment!</strong></p>
</blockquote>

<p>We’ll start with running jupyter notebook and then importing necessary libraries in our case OpenCV, Keras and sklearn.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># in your conda environment run
</code></pre></div></div>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
</pre></td><td class="code"><pre>    jupyter notebook 
</pre></td></tr></tbody></table></code></pre></figure>

<p>This should open Jupyter notebook in the default web browser.
Once open, let’s import the libraries</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td class="code"><pre>    <span class="c">#importing openCV</span>
    import cv2

    <span class="c">#importing numpy</span>
    import numpy as np

    <span class="c">#importing pandas to read the CSV file containing our data</span>
    import pandas as pd

    <span class="c">#importing keras and sub-libraries</span>
    from keras.models import Sequential
    from keras.layers import Dense
    from keras.layers import Dropout
    from keras.layers import Flatten, MaxPool2D
    from keras.layers.convolutional import Conv2D
    from keras.layers.convolutional import MaxPooling2D
    from keras import backend as K
    from keras.utils import np_utils
    from sklearn.model_selection import train_test_split 
</pre></td></tr></tbody></table></code></pre></figure>

<p><img src="" alt="" /></p>
<h5 id="step-3"><strong>Step 3</strong></h5>

<blockquote>
  <p><strong>Number plate detection:</strong></p>
</blockquote>

<p>Let’s start simple by importing a sample image of a car with a license plate and define some functions:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">extract_plate</span><span class="p">(</span><span class="n">img</span><span class="p">):</span> <span class="c1"># the function detects and perfors blurring on the number plate.
</span>	<span class="n">plate_img</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>

	<span class="c1">#Loads the data required for detecting the license plates from cascade classifier.
</span>	<span class="n">plate_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="s">'./indian_license_plate.xml'</span><span class="p">)</span>

	<span class="c1"># detects numberplates and returns the coordinates and dimensions of detected license plate's contours.
</span>	<span class="n">plate_rect</span> <span class="o">=</span> <span class="n">plate_cascade</span><span class="p">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">plate_img</span><span class="p">,</span> <span class="n">scaleFactor</span> <span class="o">=</span> <span class="mf">1.3</span><span class="p">,</span> <span class="n">minNeighbors</span> <span class="o">=</span> <span class="mi">7</span><span class="p">)</span>

	<span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="n">plate_rect</span><span class="p">:</span>
		<span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.02</span><span class="o">*</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.025</span><span class="o">*</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="c1">#parameter tuning
</span>		<span class="n">plate</span> <span class="o">=</span> <span class="n">plate_img</span><span class="p">[</span><span class="n">y</span><span class="o">+</span><span class="n">a</span><span class="p">:</span><span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="o">-</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">+</span><span class="n">b</span><span class="p">:</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="o">-</span><span class="n">b</span><span class="p">,</span> <span class="p">:]</span>
		<span class="c1"># finally representing the detected contours by drawing rectangles around the edges.
</span>		<span class="n">cv2</span><span class="p">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">plate_img</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">),</span> <span class="p">(</span><span class="mi">51</span><span class="p">,</span><span class="mi">51</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>

	<span class="k">return</span> <span class="n">plate_img</span><span class="p">,</span> <span class="n">plate</span> <span class="c1"># returning the processed image
</span> 
</pre></td></tr></tbody></table></code></pre></figure>

<p>The above function works by taking image as input, then applying ‘haar cascade’ that is pre-trained to detect Indian license plates, here the parameter scaleFactor stands for a value by which input image can be scaled for better detection of license plate (<a href="https://sites.google.com/site/5kk73gpu2012/assignment/viola-jones-face-detection#TOC-Image-Pyramid">know more</a>). minNeighbors is just a parameter to reduce false positives, if this value is low, the algorithm may be more prone to giving a misrecognized outputs. (you can download the haar cascade file as ‘indian_license_plate.xml’ file from my <a href="https://github.com/SarthakV7/AI-based-indian-license-plate-detection">github</a> profile.)</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*RFqmJj0alAKWAqyBuihosw.jpeg" />
    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*S8bTK6q1LUuChQ2Fet6yfQ.jpeg" />
    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*w_LVI7pA6CehL0P5t6LhGQ.png" />
    </div>
</div>

<p><img src="" alt="" /></p>
<h5 id="step-4"><strong>Step 4</strong></h5>

<blockquote>
  <p><strong>Performing some image processing on the License plate.</strong></p>
</blockquote>

<p>Now let’s process this image further to make the character extraction process easy. We’ll start by defining some more functions for that.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td class="code"><pre><span class="c1"># Find characters in the resulting images
</span><span class="k">def</span> <span class="nf">segment_characters</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="p">:</span>

    <span class="c1"># Preprocess cropped license plate image
</span>    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">333</span><span class="p">,</span> <span class="mi">75</span><span class="p">))</span>
    <span class="n">img_gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">img_binary</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">img_gray</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">THRESH_BINARY</span><span class="o">+</span><span class="n">cv2</span><span class="p">.</span><span class="n">THRESH_OTSU</span><span class="p">)</span>
    <span class="n">img_erode</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">erode</span><span class="p">(</span><span class="n">img_binary</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">img_dilate</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">dilate</span><span class="p">(</span><span class="n">img_erode</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>

    <span class="n">LP_WIDTH</span> <span class="o">=</span> <span class="n">img_dilate</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">LP_HEIGHT</span> <span class="o">=</span> <span class="n">img_dilate</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Make borders white
</span>    <span class="n">img_dilate</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,:]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">img_dilate</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">img_dilate</span><span class="p">[</span><span class="mi">72</span><span class="p">:</span><span class="mi">75</span><span class="p">,:]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">img_dilate</span><span class="p">[:,</span><span class="mi">330</span><span class="p">:</span><span class="mi">333</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>

    <span class="c1"># Estimations of character contours sizes of cropped license plates
</span>    <span class="n">dimensions</span> <span class="o">=</span> <span class="p">[</span><span class="n">LP_WIDTH</span><span class="o">/</span><span class="mi">6</span><span class="p">,</span> <span class="n">LP_WIDTH</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">LP_HEIGHT</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">LP_HEIGHT</span><span class="o">/</span><span class="mi">3</span><span class="p">]</span>

    <span class="c1"># Get contours within cropped license plate
</span>    <span class="n">char_list</span> <span class="o">=</span> <span class="n">find_contours</span><span class="p">(</span><span class="n">dimensions</span><span class="p">,</span> <span class="n">img_dilate</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">char_list</span>
 
</pre></td></tr></tbody></table></code></pre></figure>

<p>The above function takes in the image as input and performs the following operation on it-</p>

<ul>
  <li>
    <p>resizes it to a dimension such that all characters seem distinct and clear</p>
  </li>
  <li>
    <p>convert the colored image to a grey scaled image i.e instead of 3 channels (BGR), the image only has a single 8-bit channel with values ranging from 0–255 where 0 corresponds to black and 255 corresponds to white. We do this to prepare the image for the next process.</p>
  </li>
  <li>
    <p>now the threshold function converts the grey scaled image to a binary image i.e each pixel will now have a value of 0 or 1 where 0 corresponds to black and 1 corresponds to white. It is done by applying a threshold that has a value between 0 and 255, here the value is 200 which means in the grayscaled image for pixels having a value above 200, in the new binary image that pixel will be given a value of 1. And for pixels having value below 200, in the new binary image that pixel will be given a value of 0.</p>
  </li>
  <li>
    <p>The image is now in binary form and ready for the next process Eroding.
Eroding is a simple process used for removing unwanted pixels from the object’s boundary meaning pixels that should have a value of 0 but are having a value of 1. It works by considering each pixel in the image one by one and then considering the pixel’s neighbor (the number of neighbors depends on the kernel size), the pixel is given a value 1 only if all its neighboring pixels are 1, otherwise it is given a value of 0.</p>
  </li>
  <li>
    <p>The image is now clean and free of boundary noise, we will now dilate the image to fill up the absent pixels meaning pixels that should have a value of 1 but are having value 0. The function works similar to eroding but with a little catch, it works by considering each pixel in the image one by one and then considering the pixel’s neighbor (the number of neighbors depends on the kernel size), the pixel is given a value 1 if at least one of its neighboring pixels is 1.</p>
  </li>
  <li>
    <p>The next step now is to make the boundaries of the image white. This is to remove any out of the frame pixel in case it is present.</p>
  </li>
  <li>
    <p>Next, we define a list of dimensions that contains 4 values with which we’ll be comparing the character’s dimensions for filtering out the required characters.</p>
  </li>
  <li>
    <p>Through the above processes, we have reduced our image to a processed binary image and we are ready to pass this image for character extraction.</p>
  </li>
</ul>

<p><img src="" alt="" /></p>
<h5 id="step-5"><strong>Step 5</strong></h5>

<blockquote>
  <p><strong>Segmenting the alphanumeric characters from the license plate.</strong></p>
</blockquote>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="c1"># Match contours to license plate or character template
</span><span class="k">def</span> <span class="nf">find_contours</span><span class="p">(</span><span class="n">dimensions</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span> <span class="p">:</span>

    <span class="c1"># Find all contours in the image
</span>    <span class="n">cntrs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">findContours</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">cv2</span><span class="p">.</span><span class="n">RETR_TREE</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">CHAIN_APPROX_SIMPLE</span><span class="p">)</span>

    <span class="c1"># Retrieve potential dimensions
</span>    <span class="n">lower_width</span> <span class="o">=</span> <span class="n">dimensions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">upper_width</span> <span class="o">=</span> <span class="n">dimensions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">lower_height</span> <span class="o">=</span> <span class="n">dimensions</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">upper_height</span> <span class="o">=</span> <span class="n">dimensions</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>


    <span class="c1"># Check largest 5 or  15 contours for license plate or character respectively
</span>    <span class="n">cntrs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">cntrs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">cv2</span><span class="p">.</span><span class="n">contourArea</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:</span><span class="mi">15</span><span class="p">]</span>

    <span class="n">x_cntr_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">target_contours</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">img_res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">cntr</span> <span class="ow">in</span> <span class="n">cntrs</span> <span class="p">:</span>
        <span class="c1">#detects contour in binary image and returns the coordinates of rectangle enclosing it
</span>        <span class="n">intX</span><span class="p">,</span> <span class="n">intY</span><span class="p">,</span> <span class="n">intWidth</span><span class="p">,</span> <span class="n">intHeight</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">boundingRect</span><span class="p">(</span><span class="n">cntr</span><span class="p">)</span>

        <span class="c1">#checking the dimensions of the contour to filter out the characters by contour's size
</span>        <span class="k">if</span> <span class="n">intWidth</span> <span class="o">&gt;</span> <span class="n">lower_width</span> <span class="ow">and</span> <span class="n">intWidth</span> <span class="o">&lt;</span> <span class="n">upper_width</span> <span class="ow">and</span> <span class="n">intHeight</span> <span class="o">&gt;</span> <span class="n">lower_height</span> <span class="ow">and</span> <span class="n">intHeight</span> <span class="o">&lt;</span> <span class="n">upper_height</span> <span class="p">:</span>
            <span class="n">x_cntr_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">intX</span><span class="p">)</span> <span class="c1">#stores the x coordinate of the character's contour, to used later for indexing the contours
</span>
            <span class="n">char_copy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">44</span><span class="p">,</span><span class="mi">24</span><span class="p">))</span>
            <span class="c1">#extracting each character using the enclosing rectangle's coordinates.
</span>            <span class="n">char</span> <span class="o">=</span> <span class="n">img</span><span class="p">[</span><span class="n">intY</span><span class="p">:</span><span class="n">intY</span><span class="o">+</span><span class="n">intHeight</span><span class="p">,</span> <span class="n">intX</span><span class="p">:</span><span class="n">intX</span><span class="o">+</span><span class="n">intWidth</span><span class="p">]</span>
            <span class="n">char</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">char</span><span class="p">,</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">))</span>

            <span class="c1"># Make result formatted for classification: invert colors
</span>            <span class="n">char</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">subtract</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="n">char</span><span class="p">)</span>

            <span class="c1"># Resize the image to 24x44 with black border
</span>            <span class="n">char_copy</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">42</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">22</span><span class="p">]</span> <span class="o">=</span> <span class="n">char</span>
            <span class="n">char_copy</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">char_copy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">char_copy</span><span class="p">[</span><span class="mi">42</span><span class="p">:</span><span class="mi">44</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">char_copy</span><span class="p">[:,</span> <span class="mi">22</span><span class="p">:</span><span class="mi">24</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="n">img_res</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char_copy</span><span class="p">)</span> <span class="c1">#List that stores the character's binary image (unsorted)
</span>
    <span class="c1">#Return characters on ascending order with respect to the x-coordinate (most-left character first)
</span>
    <span class="c1">#arbitrary function that stores sorted list of character indeces
</span>    <span class="n">indices</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_cntr_list</span><span class="p">)),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">x_cntr_list</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="n">img_res_copy</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
        <span class="n">img_res_copy</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">img_res</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span><span class="c1"># stores character images according to their index
</span>    <span class="n">img_res</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">img_res_copy</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">img_res</span>
<span class="n">view</span> <span class="n">rawcharacter_detection</span><span class="p">.</span><span class="n">py</span> <span class="n">hosted</span> <span class="k">with</span> <span class="err">❤</span> <span class="n">by</span> <span class="n">GitHub</span>
 
</pre></td></tr></tbody></table></code></pre></figure>

<p>After step 4 we should have a clean binary image to work on. In this step, we will be applying some more image processing to extract the individual characters from the license plate. The steps involved will be-</p>

<ul>
  <li>Finding all the contours in the input image. The function cv2.findContours returns all the contours it finds in the image. Contours can be explained simply as a curve joining all the continuous points (along the boundary), having the same color or intensity.</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*I1-aZ-szf-SqrxueEtB-Tg.png" />
    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*8blZEtiXo9vxriC3yp1EDA.png" />
    </div>
</div>

<ul>
  <li>After finding all the contours we consider them one by one and calculate the dimension of their respective bounding rectangle. Now consider bounding rectangle is the smallest rectangle possible that contains the contour. Let me illustrate the bounding rectangle by drawing them for each character here.</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*0l5qoklROE2bdIq4JkXfuA.png" />
    </div>
</div>

<ul>
  <li>Since we have the dimensions of these bounding rectangle, all we need to do is do some parameter tuning and filter out the required rectangle containing required characters. For this, we will be performing some dimension comparison by accepting only those rectangle that have:
    <ol>
      <li>Width in the range  0, (length of the pic)/(number of characters) and,</li>
      <li>Length in a range of (width of the pic)/2, 4*(width of the pic)/5.
After this step, we should have all the characters extracted as binary images.</li>
    </ol>
  </li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*PVdInfmQoYIxyYyp81Kx1w.png" />
    </div>
</div>

<ul>
  <li>The characters may be unsorted but don’t worry, the last few lines of the code take care of that. It sorts the character according to the position of their bounding rectangle from the left boundary of the plate.</li>
</ul>

<p><img src="" alt="" /></p>
<h5 id="step-6"><strong>Step 6</strong></h5>

<blockquote>
  <p><strong>Creating a Machine Learning model and training it for the characters.</strong></p>
</blockquote>

<ul>
  <li>The data is all clean and ready, now it’s time do create a Neural Network that will be intelligent enough to recognize the characters after training.</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2048/1*KhUiEJdZy42JfkCfwm7jjg.jpeg" />
    </div>
</div>

<p><img src="" alt="" /></p>
<ul>
  <li>For modeling, we will be using a Convolutional Neural Network with 3 layers.</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="code"><pre><span class="c"># create model</span>
model <span class="o">=</span> Sequential<span class="o">()</span>
model.add<span class="o">(</span>Conv2D<span class="o">(</span><span class="nv">filters</span><span class="o">=</span>32, <span class="nv">kernel_size</span><span class="o">=(</span>5,5<span class="o">)</span>, <span class="nv">input_shape</span><span class="o">=(</span>28, 28, 1<span class="o">)</span>, <span class="nv">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="o">))</span>
model.add<span class="o">(</span>MaxPooling2D<span class="o">(</span><span class="nv">pool_size</span><span class="o">=(</span>2, 2<span class="o">)))</span>
model.add<span class="o">(</span>Dropout<span class="o">(</span><span class="nv">rate</span><span class="o">=</span>0.4<span class="o">))</span>
model.add<span class="o">(</span>Flatten<span class="o">())</span>
model.add<span class="o">(</span>Dense<span class="o">(</span><span class="nv">units</span><span class="o">=</span>128, <span class="nv">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="o">))</span>
model.add<span class="o">(</span>Dense<span class="o">(</span><span class="nv">units</span><span class="o">=</span>36, <span class="nv">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="o">))</span>
</pre></td></tr></tbody></table></code></pre></figure>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2248/1*FAMyA1skMbdXYQlmUM6Kfw.png" />
    </div>
</div>

<ul>
  <li>
    <p>To keep the model simple, we’ll start by creating a sequential object.</p>
  </li>
  <li>
    <p>The first layer will be a convolutional layer with 32 output filters, a convolution window of size (5,5), and ‘Relu’ as activation function.</p>
  </li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*njuH4XVXf-l9pR_RorUOrA.png" />
    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*iUxZ6ZNaizs2DzhDvTWDgg.png" />
    </div>
</div>

<ul>
  <li>Next, we’ll be adding a max-pooling layer with a window size of (2,2).
<strong>Max pooling</strong> is a sample-based discretization process. The objective is to down-sample an input representation (image, hidden-<strong>layer</strong> output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned.</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/10140/1*cEpnL1pqYe45cBZIfOxASw.png" />
    </div>
</div>

<ul>
  <li>
    <p>Now, we will be adding some dropout rate to take care of overfitting.
<strong>Dropout</strong> is a regularization hyperparameter initialized to prevent Neural Networks from Overfitting. Dropout is a technique where randomly selected neurons are ignored during training. They are “<strong>dropped</strong>-<strong>out</strong>” randomly. We have chosen a dropout rate of 0.4 meaning 60% of the node will be retained.</p>
  </li>
  <li>
    <p>Now it’s time to flatten the node data so we add a flatten layer for that. The flatten layer takes data from the previous layer and represents it in a single dimension.</p>
  </li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*BLP5zEDWc6kwBpThM5jFjQ.png" />
    </div>
</div>

<ul>
  <li>Finally, we will be adding 2 dense layers, one with the dimensionality of the output space as 128, activation function=’ReLU’ and other, our final layer with 36 outputs for categorizing the 26 alphabets (A-Z) + 10 digits (0–9) and activation function= ‘softmax’</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*_uXiq8n5QvQzlJLNjZRLSg.png" />
    </div>
</div>

<p><img src="" alt="" /></p>
<h5 id="step-7"><strong>Step 7</strong></h5>

<blockquote>
  <p><strong>Training our CNN model.</strong></p>
</blockquote>

<ul>
  <li>
    <p>The data we will be using contains images of alphabets (A-Z) and digits (0–9) of size 28x28, also the data is balanced so we won’t have to do any kind of data tuning here.</p>
  </li>
  <li>
    <p>I’ve created a <a href="https://github.com/SarthakV7/AI-based-indian-license-plate-detection/blob/master/data.zip">zip file</a> that contains data as per the directory structure below, with a train test split of 80:20</p>
  </li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/0*uXcMknHKArBw3f5J.jpeg" />
    </div>
</div>

<ul>
  <li>
    <p>We’ll be using ImageDataGenerator class available in keras to generate some more data using image augmentation techniques like width shift, height shift. To know more about ImageDataGenerator, please check out <a href="https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720">this</a> nice blog.</p>
  </li>
  <li>
    <p>Width shift: Accepts a float value denoting by what fraction the image will be shifted left and right.
Height shift: Accepts a float value denoting by what fraction the image will be shifted up and down.</p>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="code"><pre> <span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>
<span class="n">train_datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">width_shift_range</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">height_shift_range</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

<span class="n">train_generator</span> <span class="o">=</span> <span class="n">train_datagen</span><span class="p">.</span><span class="n">flow_from_directory</span><span class="p">(</span>
        <span class="s">'data/train'</span><span class="p">,</span>  <span class="c1"># this is the target directory
</span>        <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span>  <span class="c1"># all images will be resized to 28x28
</span>        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">class_mode</span><span class="o">=</span><span class="s">'categorical'</span><span class="p">)</span>

<span class="n">validation_generator</span> <span class="o">=</span> <span class="n">train_datagen</span><span class="p">.</span><span class="n">flow_from_directory</span><span class="p">(</span>
        <span class="s">'data/val'</span><span class="p">,</span>  <span class="c1"># this is the target directory
</span>        <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span>  <span class="c1"># all images will be resized to 28x28
</span>        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">class_mode</span><span class="o">=</span><span class="s">'categorical'</span><span class="p">)</span>
 
</pre></td></tr></tbody></table></code></pre></figure>

<ul>
  <li>It’s time to train our model now!
we will use ‘categorical_crossentropy’ as loss function, ‘Adam’ as optimization function and ‘Accuracy’ as our error matrix.</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="code"><pre> <span class="kn">import</span> <span class="nn">datetime</span>
<span class="k">class</span> <span class="nc">stop_training_callback</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">Callback</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
    <span class="k">if</span><span class="p">(</span><span class="n">logs</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'val_acc'</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.992</span><span class="p">):</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">log_dir</span><span class="o">=</span><span class="s">"logs/fit/"</span> <span class="o">+</span> <span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">().</span><span class="n">strftime</span><span class="p">(</span><span class="s">"%Y%m%d-%H%M%S"</span><span class="p">)</span>
<span class="n">tensorboard_callback</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensorboard_callback</span><span class="p">,</span> <span class="n">stop_training_callback</span><span class="p">()]</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">train_generator</span><span class="p">,</span>
      <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">train_generator</span><span class="p">.</span><span class="n">samples</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span>
      <span class="n">validation_data</span> <span class="o">=</span> <span class="n">validation_generator</span><span class="p">,</span>
      <span class="n">validation_steps</span> <span class="o">=</span> <span class="n">validation_generator</span><span class="p">.</span><span class="n">samples</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span>
      <span class="n">epochs</span> <span class="o">=</span> <span class="mi">80</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
 
</pre></td></tr></tbody></table></code></pre></figure>

<ul>
  <li>After training for 23 epochs, the model achieved an accuracy of 99.54%.</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/4332/1*HAA_UPvZRihw3i17aYLvVA.png" />
    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2692/1*o9wFBmX69Nm44RbMngw6dA.png" />
    </div>
</div>

<p><img src="" alt="" /></p>
<h5 id="step-8"><strong>Step 8</strong></h5>

<blockquote>
  <p><strong>The output.</strong></p>
</blockquote>

<p>Finally, its time to test our model, remember the binary images of extracted characters from number plate? Let’s feed the images to our model!</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/3540/1*esXDwU6Brah9mL42BY0M-A.png" />
    </div>
</div>

<p>The output-</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-1">
        <img class="img-fluid rounded z-depth-0" src="https://cdn-images-1.medium.com/max/2000/1*9OWCIVp8wZvYbgajn_mC-w.png" />
    </div>
</div>

<p><img src="" alt="" /></p>

<blockquote>
  <p><strong>Final comment</strong></p>
</blockquote>

<p>Thank you guys for reading the blog, hope this project is useful for some of you aspiring to do projects on OCR, image processing, Machine Learning, IoT.</p>

<p>And if you have any doubts regarding this project, please leave a comment in the response section.</p>

<p>The full project is available on my Github:
<a href="https://github.com/SarthakV7/AI-based-indian-license-plate-detection">https://github.com/SarthakV7/AI-based-indian-license-plate-detection</a></p>

<p>Find me on LinkedIn: <a href="http://www.linkedin.com/in/sarthak-vajpayee">www.linkedin.com/in/sarthak-vajpayee</a></p>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Sarthak  Vajpayee.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/my_folio/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/my_folio/assets/js/common.js"></script>


</html>
